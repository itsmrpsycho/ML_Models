{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Dataset analysis & Pre Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1143, 13)\n",
      "column fixed acidity: \n",
      "mean = 8.311111111111112 std dev = 1.7468303726275016 min = 4.6 max = 15.9\n",
      "column volatile acidity: \n",
      "mean = 0.5313385826771653 std dev = 0.17955459612835617 min = 0.12 max = 1.58\n",
      "column citric acid: \n",
      "mean = 0.2683639545056868 std dev = 0.19659979421574741 min = 0.0 max = 1.0\n",
      "column residual sugar: \n",
      "mean = 2.5321522309711284 std dev = 1.355324197143589 min = 0.9 max = 15.5\n",
      "column chlorides: \n",
      "mean = 0.08693263342082239 std dev = 0.04724665655215518 min = 0.012 max = 0.611\n",
      "column free sulfur dioxide: \n",
      "mean = 15.615485564304462 std dev = 10.246001115067605 min = 1.0 max = 68.0\n",
      "column total sulfur dioxide: \n",
      "mean = 45.91469816272966 std dev = 32.76778677994138 min = 6.0 max = 289.0\n",
      "column density: \n",
      "mean = 0.9967304111986001 std dev = 0.001924224834379527 min = 0.99007 max = 1.00369\n",
      "column pH: \n",
      "mean = 3.3110148731408575 std dev = 0.15659551281704315 min = 2.74 max = 4.01\n",
      "column sulphates: \n",
      "mean = 0.6577077865266842 std dev = 0.1703241580362606 min = 0.33 max = 2.0\n",
      "column alcohol: \n",
      "mean = 10.442111402741325 std dev = 1.0817221048833654 min = 8.4 max = 14.9\n",
      "column quality: \n",
      "mean = 5.657042869641295 std dev = 0.805471666920189 min = 3 max = 8\n",
      "column Id: \n",
      "mean = 804.9693788276466 std dev = 463.79409851409224 min = 0 max = 1597\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "dat1 = pd.read_csv(\"./bin/WineQT.csv\")\n",
    "print(dat1.shape)\n",
    "for i in dat1.columns:\n",
    "    print(f\"column {i}: \")\n",
    "    column = dat1[i].to_numpy()\n",
    "    print(f\"mean = {np.mean(column)}\",end=\" \")\n",
    "    print(f\"std dev = {np.std(column)}\",end=\" \")\n",
    "    print(f\"min = {np.min(column)}\",end=\" \")\n",
    "    print(f\"max = {np.max(column)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "labels_column = 'quality'\n",
    "labels = dat1[labels_column]\n",
    "\n",
    "plt.figure(figsize=(4, 3))\n",
    "plt.hist(labels, bins=len(labels.unique()), edgecolor='black', color='cyan')\n",
    "plt.title(f'Distribution of {labels_column} label')\n",
    "plt.xlabel(labels_column)\n",
    "plt.ylabel('Count')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "X = dat1.drop(columns=['quality','Id']).to_numpy()\n",
    "Y = dat1['quality'].to_numpy()\n",
    "\n",
    "X_train, X_temp, Y_train, Y_temp = train_test_split(X, Y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, Y_val, Y_test = train_test_split(X_temp, Y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Handle Missing or Inconsistent Data (if necessary)\n",
    "# Use SimpleImputer to fill missing values with the mean or other strategies\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train = imputer.fit_transform(X_train)\n",
    "X_val = imputer.transform(X_val)\n",
    "X_test = imputer.transform(X_test)\n",
    "\n",
    "# Normalize and Standardize Data\n",
    "# Use StandardScaler to standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2: Model Building from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "class MultinomialLogisticRegression:\n",
    "\n",
    "    def __init__(self, num_features, num_classes, learning_rate=0.01, epochs=1000,printOutput=True):\n",
    "        self.num_features = num_features\n",
    "        self.num_classes = num_classes\n",
    "        self.classes = None\n",
    "        self.d = {}\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.W = np.random.rand(num_features, num_classes)\n",
    "        self.b = np.zeros(num_classes)\n",
    "        self.printOutput = printOutput\n",
    "\n",
    "    def printMetrics(self,preds,true):\n",
    "        print(f\"Accuracy = \\t {accuracy_score(preds,true)}\")\n",
    "        print(f\"precision micro = \\t {precision_score(preds,true,average='micro',zero_division=1)}\",end=\"\\t\")\n",
    "        print(f\"precision macro = \\t {precision_score(preds,true,average='macro',zero_division=1)}\")\n",
    "        print(f\"recall micro = \\t\\t {recall_score(preds,true,average='micro',zero_division=1)}\",end=\" \\t\")\n",
    "        print(f\"recall macro = \\t\\t {recall_score(preds,true,average='macro',zero_division=1)}\")\n",
    "        print(f\"f1_score micro = \\t {f1_score(preds,true,average='micro',zero_division=1)}\",end=\"\\t\")\n",
    "        print(f\"f1_score macro = \\t {f1_score(preds,true,average='macro',zero_division=1)}\\n\")\n",
    "        \n",
    "\n",
    "    def softmax(self, logits):\n",
    "        exp_logits = np.exp(logits - np.max(logits, axis=1, keepdims=True))\n",
    "        return exp_logits / np.sum(exp_logits, axis=1, keepdims=True)\n",
    "\n",
    "    def cross_entropy_loss(self, oneHotTrueProbs, pred_probs):\n",
    "        epsilon = 1e-15\n",
    "        n = oneHotTrueProbs.shape[0]\n",
    "\n",
    "        pred_probs = np.maximum(epsilon, pred_probs)\n",
    "        loss = -np.sum(oneHotTrueProbs * np.log(pred_probs))\n",
    "        \n",
    "        return loss/n\n",
    "\n",
    "    def gradient_descent(self, X, oneHotTrueProbs, pred_probs):\n",
    "        n = oneHotTrueProbs.shape[0]\n",
    "        dW = np.dot(X.T, (pred_probs - oneHotTrueProbs)) / n\n",
    "        db = np.sum(pred_probs - oneHotTrueProbs) / n\n",
    "        self.W -= self.learning_rate * dW\n",
    "        self.b -= self.learning_rate * db\n",
    "    \n",
    "    def oneHotLabels(self, Y):\n",
    "        oneHotTrueProbs = pd.get_dummies(Y).to_numpy()\n",
    "        return oneHotTrueProbs\n",
    "\n",
    "    def predict(self, X):\n",
    "        n = X.shape[0]\n",
    "        logits = np.dot(X, self.W) + self.b\n",
    "        probabilities = self.softmax(logits)\n",
    "        output = np.zeros(X.shape[0])\n",
    "        for i in range(n):\n",
    "            output[i] = self.d[np.argmax(probabilities[i])]\n",
    "        return output\n",
    "\n",
    "    def evaluate_wandb(self,X,Y):\n",
    "        logits = X_train @ self.W + self.b\n",
    "        probabilities = self.softmax(logits)\n",
    "        oneHotY = self.oneHotLabels(Y_train)\n",
    "        loss = self.cross_entropy_loss(oneHotY, probabilities)\n",
    "        acc = accuracy_score(self.predict(X),Y)\n",
    "\n",
    "        return loss, acc\n",
    "\n",
    "    def fit(self, X_train, Y_train, X_val, Y_val):\n",
    "        self.classes = np.zeros(self.num_classes)\n",
    "        self.d = {}\n",
    "        classes = np.unique(Y_train)\n",
    "        for i in range (len(classes)):\n",
    "            self.classes[i] = classes[i]\n",
    "            self.d[i] = classes[i]\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "\n",
    "            logits = X_train @ self.W + self.b\n",
    "            probabilities = self.softmax(logits)\n",
    "\n",
    "            oneHotY = self.oneHotLabels(Y_train)\n",
    "            loss = self.cross_entropy_loss(oneHotY, probabilities)\n",
    "\n",
    "            self.gradient_descent(X_train, oneHotY, probabilities)\n",
    "\n",
    "            if (self.printOutput) and (epoch % 250 == 0):\n",
    "                print(f'Epoch {epoch}: Loss = {loss}')\n",
    "\n",
    "                predictions = self.predict(X_val)\n",
    "                self.printMetrics(predictions, Y_val)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Loss = 2.406355163165565\n",
      "Accuracy = \t 0.07602339181286549\n",
      "precision micro = \t 0.07602339181286549\tprecision macro = \t 0.3133379795566175\n",
      "recall micro = \t\t 0.07602339181286549 \trecall macro = \t\t 0.06310050993022008\n",
      "f1_score micro = \t 0.07602339181286549\tf1_score macro = \t 0.2262302919165664\n",
      "\n",
      "Epoch 250: Loss = 1.7571810668552643\n",
      "Accuracy = \t 0.2631578947368421\n",
      "precision micro = \t 0.2631578947368421\tprecision macro = \t 0.589979091995221\n",
      "recall micro = \t\t 0.2631578947368421 \trecall macro = \t\t 0.23973661473661476\n",
      "f1_score micro = \t 0.2631578947368421\tf1_score macro = \t 0.19503878775563224\n",
      "\n",
      "Epoch 500: Loss = 1.5689632245529628\n",
      "Accuracy = \t 0.3742690058479532\n",
      "precision micro = \t 0.3742690058479532\tprecision macro = \t 0.39010022567370234\n",
      "recall micro = \t\t 0.3742690058479532 \trecall macro = \t\t 0.25648831376540293\n",
      "f1_score micro = \t 0.37426900584795314\tf1_score macro = \t 0.5474704052492355\n",
      "\n",
      "Epoch 750: Loss = 1.5010880192917448\n",
      "Accuracy = \t 0.45614035087719296\n",
      "precision micro = \t 0.45614035087719296\tprecision macro = \t 0.4434986061330147\n",
      "recall micro = \t\t 0.45614035087719296 \trecall macro = \t\t 0.27904761904761904\n",
      "f1_score micro = \t 0.45614035087719296\tf1_score macro = \t 0.5729230733524422\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = MultinomialLogisticRegression(num_features=X_train.shape[1], num_classes=len(np.unique(Y_train)))\n",
    "model.fit(X_train, Y_train,X_val,Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = \t 0.5\n",
      "precision micro = \t 0.5\tprecision macro = \t 0.46640038731542005\n",
      "recall micro = \t\t 0.5 \trecall macro = \t\t 0.2624737529917918\n",
      "f1_score micro = \t 0.5\tf1_score macro = \t 0.5778724747474747\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "model.printMetrics(predictions,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mits_mrpsycho\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/itsmrpsycho/Study/SMAI/Assignment 3/assignment-3-itsmrpsycho/wandb/run-20231023_201641-2m73cvf9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/its_mrpsycho/SMAI_A3_q1-MultinomialLogisticRegression/runs/2m73cvf9' target=\"_blank\">glad-bush-2</a></strong> to <a href='https://wandb.ai/its_mrpsycho/SMAI_A3_q1-MultinomialLogisticRegression' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/its_mrpsycho/SMAI_A3_q1-MultinomialLogisticRegression' target=\"_blank\">https://wandb.ai/its_mrpsycho/SMAI_A3_q1-MultinomialLogisticRegression</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/its_mrpsycho/SMAI_A3_q1-MultinomialLogisticRegression/runs/2m73cvf9' target=\"_blank\">https://wandb.ai/its_mrpsycho/SMAI_A3_q1-MultinomialLogisticRegression/runs/2m73cvf9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "import numpy as np\n",
    "\n",
    "# Initialize W&B\n",
    "wandb.init(project=\"SMAI_A3_q1-MultinomialLogisticRegression\", entity=\"its_mrpsycho\")\n",
    "\n",
    "# Define a function to log to W&B\n",
    "def log_to_wandb(loss, accuracy, learning_rate, epochs):\n",
    "    wandb.log({\n",
    "        \"loss\": loss,\n",
    "        \"accuracy\": accuracy,\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"epochs\": epochs\n",
    "    })\n",
    "\n",
    "# Hyperparameter Search\n",
    "learning_rates = [0.01, 0.001, 0.0001]\n",
    "epochs = [100, 200, 500, 1000, 1500]\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for num_epochs in epochs:\n",
    "        # Create and train your model with the current hyperparameters\n",
    "        model = MultinomialLogisticRegression(num_features=X_train.shape[1], num_classes=len(np.unique(Y_train)), learning_rate=lr, epochs=num_epochs, printOutput=False)\n",
    "        model.fit(X_train, Y_train, X_val, Y_val)\n",
    "\n",
    "        # Evaluate on the validation set\n",
    "        val_loss, val_accuracy = model.evaluate_wandb(X_val, Y_val)\n",
    "\n",
    "        # Log the results to W&B\n",
    "        log_to_wandb(val_loss, val_accuracy, lr, num_epochs)\n",
    "\n",
    "# Analyze the results in the W&B dashboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         3.0       0.00      1.00      0.00         0\n",
      "         4.0       0.00      0.00      1.00         6\n",
      "         5.0       0.70      0.74      0.72        81\n",
      "         6.0       0.50      0.18      0.27        65\n",
      "         7.0       0.28      0.76      0.41        17\n",
      "         8.0       0.00      0.00      1.00         3\n",
      "\n",
      "    accuracy                           0.49       172\n",
      "   macro avg       0.25      0.45      0.57       172\n",
      "weighted avg       0.55      0.49      0.53       172\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "modelOptimal = MultinomialLogisticRegression(num_features=X_train.shape[1], num_classes=len(np.unique(Y_train)), learning_rate=0.01, epochs=1500, printOutput=False)\n",
    "\n",
    "modelOptimal.fit(X_train, Y_train, X_val, Y_val)\n",
    "Y_pred = modelOptimal.predict(X_test)\n",
    "report = classification_report(Y_test, Y_pred,zero_division=1)\n",
    "\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coding",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
